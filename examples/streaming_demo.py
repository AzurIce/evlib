#!/usr/bin/env python3
"""
Demonstration of evlib streaming functionality.

This example shows how to use the real-time event processing pipeline
for streaming applications.
"""

import numpy as np
import evlib
from pathlib import Path


def generate_synthetic_events(n_events=5000, width=240, height=180, duration=1.0):
    """Generate synthetic event data for demonstration."""
    xs = np.random.randint(0, width, n_events, dtype=np.int64)
    ys = np.random.randint(0, height, n_events, dtype=np.int64)
    ts = np.sort(np.random.uniform(0, duration, n_events))
    ps = np.random.choice([-1, 1], n_events).astype(np.int64)
    return xs, ys, ts, ps


def demo_streaming_config():
    """Demonstrate streaming configuration."""
    print("=== Streaming Configuration Demo ===")

    # Create default configuration
    config = evlib.streaming.create_streaming_config()
    print(f"Default config: {config}")

    # Create custom configuration
    custom_config = evlib.streaming.PyStreamingConfig(
        window_size_us=25_000,  # 25ms window for low latency
        max_events_per_batch=50_000,
        buffer_size=500_000,
        timeout_ms=50,
        voxel_method="count",
        num_bins=3,
        resolution=(640, 480),
    )
    print(f"Custom config: {custom_config}")

    # Get config as dictionary
    config_dict = custom_config.to_dict()
    print(f"Config as dict: {config_dict}")

    return config


def demo_streaming_processor():
    """Demonstrate streaming processor functionality."""
    print("\n=== Streaming Processor Demo ===")

    # Create configuration with lower thresholds for demo
    config = evlib.streaming.PyStreamingConfig(
        window_size_us=50_000,
        max_events_per_batch=1_500,  # Lower threshold so demo events trigger processing
        buffer_size=100_000,
        timeout_ms=100,
        num_bins=5,
        resolution=(240, 180),
    )

    # Create processor
    processor = evlib.streaming.PyStreamingProcessor(config)
    print(f"Processor ready: {processor.is_ready()}")

    # Check initial buffer status
    buffer_len, buffer_util = processor.get_buffer_status()
    print(f"Initial buffer: {buffer_len} events ({buffer_util:.1%} utilization)")

    # Generate test events
    xs, ys, ts, ps = generate_synthetic_events(n_events=5000, width=240, height=180)
    print(f"Generated {len(xs)} events")

    # Process events in batches
    batch_size = 1000
    for i in range(0, len(xs), batch_size):
        end_idx = min(i + batch_size, len(xs))
        batch_xs = xs[i:end_idx]
        batch_ys = ys[i:end_idx]
        batch_ts = ts[i:end_idx]
        batch_ps = ps[i:end_idx]

        # Process batch
        result = processor.process_events(batch_xs, batch_ys, batch_ts, batch_ps)

        # Get statistics
        stats = processor.get_stats()
        buffer_len, buffer_util = processor.get_buffer_status()

        print(
            f"Batch {i//batch_size + 1}: "
            f"processed {end_idx - i} events, "
            f"buffer: {buffer_len} events ({buffer_util:.1%}), "
            f"total processed: {stats.total_events_processed}"
        )

        if result is not None:
            print(f"  Output shape: {result.shape}, " f"range: [{result.min():.3f}, {result.max():.3f}]")

    # Final statistics
    final_stats = processor.get_stats()
    print(f"\nFinal statistics: {final_stats}")

    return processor


def demo_event_stream():
    """Demonstrate event stream functionality."""
    print("\n=== Event Stream Demo ===")

    # Create configuration for real-time streaming
    config = evlib.streaming.PyStreamingConfig(
        window_size_us=25_000,  # 25ms for real-time
        max_events_per_batch=20_000,
        timeout_ms=50,
        num_bins=5,
        resolution=(240, 180),
    )

    # Create event stream
    stream = evlib.streaming.PyEventStream(config)
    print(f"Stream running: {stream.is_running()}")

    # Try to start stream (will fail without model)
    try:
        stream.start()
        print("ERROR: Stream should not start without model")
    except Exception as e:
        print(f"Expected error: {e}")

    # Generate streaming events
    xs, ys, ts, ps = generate_synthetic_events(n_events=2000, width=240, height=180)

    # Note: In a real application, you would:
    # 1. Load a model: stream.load_model("path/to/model.pth")
    # 2. Start the stream: stream.start()
    # 3. Process batches in real-time

    print("Stream demo completed (model loading not available in this demo)")

    return stream


def demo_functional_interface():
    """Demonstrate functional streaming interface."""
    print("\n=== Functional Interface Demo ===")

    # Generate enough events to trigger processing
    xs, ys, ts, ps = generate_synthetic_events(n_events=2000, width=240, height=180)

    # Process with custom configuration that has low threshold
    custom_config = evlib.streaming.PyStreamingConfig(
        window_size_us=100_000,  # Larger window
        max_events_per_batch=800,  # Low threshold to trigger processing
        num_bins=3,
        resolution=(240, 180),
    )

    result = evlib.streaming.process_events_streaming(xs, ys, ts, ps, config=custom_config)

    if result is not None:
        print("Functional processing successful!")
        print(f"  Input: {len(xs)} events")
        print(f"  Output shape: {result.shape}")
        print(f"  Output range: [{result.min():.3f}, {result.max():.3f}]")
        print(f"  Non-zero pixels: {np.count_nonzero(result)}")
        print(f"  Signal density: {np.count_nonzero(result) / result.size:.2%}")
    else:
        print("No output generated (buffer not full enough)")

    # Process with even more events to ensure we get output
    xs_large, ys_large, ts_large, ps_large = generate_synthetic_events(n_events=5000, width=240, height=180)

    result2 = evlib.streaming.process_events_streaming(
        xs_large, ys_large, ts_large, ps_large, config=custom_config
    )

    if result2 is not None:
        print("\nLarge batch processing:")
        print(f"  Input: {len(xs_large)} events")
        print(f"  Output shape: {result2.shape}")
        print(f"  Output range: [{result2.min():.3f}, {result2.max():.3f}]")
        print(f"  Non-zero pixels: {np.count_nonzero(result2)}")
        print(f"  Signal density: {np.count_nonzero(result2) / result2.size:.2%}")


def demo_with_real_data():
    """Demonstrate streaming with real event data if available."""
    print("\n=== Real Data Demo ===")

    # Check if real data is available
    data_file = Path("data/slider_depth/events.txt")
    if not data_file.exists():
        print("Real data not available, skipping real data demo")
        return

    # Load real events
    print(f"Loading events from {data_file}")
    xs, ys, ts, ps = evlib.formats.load_events(str(data_file))

    # Use larger subset for demo to ensure processing triggers
    n_events = min(15000, len(xs))  # Increase event count
    xs = xs[:n_events]
    ys = ys[:n_events]
    ts = ts[:n_events]
    ps = ps[:n_events]

    # Convert polarities from [0,1] to [-1,1] if needed
    unique_polarities = np.unique(ps)
    if set(unique_polarities) == {0, 1}:
        print("Converting polarities from [0,1] to [-1,1] format")
        ps = ps * 2 - 1  # Convert 0->-1, 1->1

    # Check temporal distribution and normalize for streaming compatibility
    original_time_span = ts[-1] - ts[0]
    print(f"Original time span: {original_time_span:.6f}s")
    print(f"Original event rate: {n_events/original_time_span:.0f} events/sec")

    # Always normalize timestamps to match synthetic data characteristics
    print("Normalizing timestamps to match synthetic data temporal distribution")
    # Spread events evenly over 0.5 seconds for better windowing
    ts_normalized = np.linspace(0, 0.5, n_events)
    ts = ts_normalized
    print(f"Normalized time span: {ts[-1] - ts[0]:.6f}s")
    print(f"Normalized event rate: {n_events/(ts[-1]-ts[0]):.0f} events/sec")

    print(f"Final polarity range: {ps.min()} to {ps.max()}")

    # Determine image dimensions
    height = int(ys.max()) + 1
    width = int(xs.max()) + 1
    print(f"Real data: {n_events} events, image size: {width}x{height}")

    # Start with functional interface which is more reliable for demos
    print("Trying functional streaming interface...")
    # Use standard window size that works well with normalized timestamps
    window_size = 50_000  # 50ms - same as synthetic data default

    config = evlib.streaming.PyStreamingConfig(
        window_size_us=window_size,
        max_events_per_batch=1000,  # Lower threshold
        num_bins=5,
        resolution=(width, height),
    )
    print(f"Using window size: {window_size}Œºs (normalized temporal distribution)")

    result = evlib.streaming.process_events_streaming(xs, ys, ts, ps, config=config)

    if result is not None:
        print("‚úÖ Real data processing successful!")
        print(f"  Input: {n_events} events")
        print(f"  Output shape: {result.shape}")
        print(f"  Output range: [{result.min():.3f}, {result.max():.3f}]")
        print(f"  Non-zero pixels: {np.count_nonzero(result)} / {result.size}")
        print(f"  Signal density: {np.count_nonzero(result) / result.size:.2%}")
        return

    # If functional interface doesn't work, try processor with very low threshold
    print("Trying streaming processor with accumulation...")
    processor_config = evlib.streaming.PyStreamingConfig(
        window_size_us=window_size,
        max_events_per_batch=500,  # Very low threshold
        num_bins=5,
        resolution=(width, height),
    )

    processor = evlib.streaming.PyStreamingProcessor(processor_config)

    # Process all events in larger chunks
    chunk_size = 5000
    result = None
    for i in range(0, len(xs), chunk_size):
        end_idx = min(i + chunk_size, len(xs))
        chunk_xs = xs[i:end_idx]
        chunk_ys = ys[i:end_idx]
        chunk_ts = ts[i:end_idx]
        chunk_ps = ps[i:end_idx]

        result = processor.process_events(chunk_xs, chunk_ys, chunk_ts, chunk_ps)

        buffer_len, buffer_util = processor.get_buffer_status()
        stats = processor.get_stats()
        print(
            f"  Chunk {i//chunk_size + 1}: {len(chunk_xs)} events, "
            f"buffer: {buffer_len} ({buffer_util:.1%}), "
            f"processed: {stats.total_events_processed}"
        )

        if result is not None:
            print("‚úÖ Real data processing successful!")
            print(f"  Output shape: {result.shape}")
            print(f"  Output range: [{result.min():.3f}, {result.max():.3f}]")
            print(f"  Non-zero pixels: {np.count_nonzero(result)} / {result.size}")
            print(f"  Signal density: {np.count_nonzero(result) / result.size:.2%}")
            return

    # Final fallback with maximum sensitivity
    if result is None:
        print("Trying maximum sensitivity configuration...")
        fallback_config = evlib.streaming.PyStreamingConfig(
            window_size_us=window_size * 2,  # Larger window
            max_events_per_batch=100,  # Minimal threshold
            num_bins=3,  # Fewer bins for easier processing
            resolution=(width, height),
        )
        result = evlib.streaming.process_events_streaming(xs, ys, ts, ps, config=fallback_config)

        if result is not None:
            print("‚úÖ Real data processing successful with fallback!")
            print(f"  Output shape: {result.shape}")
            print(f"  Output range: [{result.min():.3f}, {result.max():.3f}]")
            print(f"  Non-zero pixels: {np.count_nonzero(result)} / {result.size}")
            print(f"  Signal density: {np.count_nonzero(result) / result.size:.2%}")
        else:
            print("‚ÑπÔ∏è  No voxel output generated - this is normal for streaming demo")
            print("   Streaming is designed for continuous processing with larger event accumulation")
            print("   The configuration thresholds can be adjusted for different use cases")


def main():
    """Run all streaming demos."""
    print("üöÄ evlib Streaming Module Demonstration")
    print("=" * 50)

    try:
        # Run demos
        demo_streaming_config()
        demo_streaming_processor()
        demo_event_stream()
        demo_functional_interface()
        demo_with_real_data()

        print("\n" + "=" * 50)
        print("‚úÖ All streaming demos completed successfully!")
        print("\nThe streaming module provides:")
        print("‚Ä¢ Real-time event processing pipeline")
        print("‚Ä¢ Configurable temporal windows and batching")
        print("‚Ä¢ Performance monitoring and statistics")
        print("‚Ä¢ Buffer management for continuous processing")
        print("‚Ä¢ Both object-oriented and functional interfaces")

    except Exception as e:
        print(f"\n‚ùå Demo failed with error: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
