{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Camera Simulation in evlib\n",
    "\n",
    "This notebook demonstrates evlib's comprehensive event simulation capabilities, including ESIM-style simulation, noise models, and video-to-events conversion with GStreamer integration.\n",
    "\n",
    "## Features Covered:\n",
    "- ESIM-style event simulation from video/webcam\n",
    "- Realistic noise models (shot noise, thermal noise, refractory period)\n",
    "- Video processing pipeline with multiple formats\n",
    "- GStreamer integration for live video capture\n",
    "- Advanced simulation parameters and tuning\n",
    "- Event validation and quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import evlib\n",
    "    print(\"‚úÖ evlib imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import evlib: {e}\")\n",
    "    raise\n",
    "\n",
    "# Optional: Check for video processing capabilities\n",
    "try:\n",
    "    import cv2\n",
    "    print(\"‚úÖ OpenCV available for video processing\")\n",
    "    CV2_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  OpenCV not available - using synthetic data\")\n",
    "    CV2_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ESIM Simulation Fundamentals\n",
    "\n",
    "The Event-based Simulator (ESIM) generates events based on brightness changes between frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_esim_principles():\n",
    "    \"\"\"Demonstrate the fundamental principles of ESIM simulation\"\"\"\n",
    "    \n",
    "    print(\"ESIM Event Simulation Principles:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create synthetic frame sequence\n",
    "    width, height = 64, 64\n",
    "    num_frames = 5\n",
    "    \n",
    "    frames = []\n",
    "    for i in range(num_frames):\n",
    "        # Create a moving bright spot\n",
    "        frame = np.zeros((height, width), dtype=np.float32)\n",
    "        center_x = int(width * (i + 1) / (num_frames + 1))\n",
    "        center_y = height // 2\n",
    "        \n",
    "        # Draw a bright circle\n",
    "        y, x = np.ogrid[:height, :width]\n",
    "        mask = (x - center_x)**2 + (y - center_y)**2 <= 5**2\n",
    "        frame[mask] = 1.0\n",
    "        \n",
    "        frames.append(frame)\n",
    "    \n",
    "    # Simulate ESIM event generation\n",
    "    def generate_events_esim(frame1, frame2, threshold_pos=0.1, threshold_neg=0.1):\n",
    "        \"\"\"Generate events using ESIM principles\"\"\"\n",
    "        \n",
    "        # Compute log brightness change\n",
    "        log_frame1 = np.log(frame1 + 1e-6)  # Add small epsilon to avoid log(0)\n",
    "        log_frame2 = np.log(frame2 + 1e-6)\n",
    "        log_change = log_frame2 - log_frame1\n",
    "        \n",
    "        # Find pixels exceeding thresholds\n",
    "        pos_events = log_change > threshold_pos\n",
    "        neg_events = log_change < -threshold_neg\n",
    "        \n",
    "        # Extract event coordinates\n",
    "        pos_y, pos_x = np.where(pos_events)\n",
    "        neg_y, neg_x = np.where(neg_events)\n",
    "        \n",
    "        # Combine events\n",
    "        xs = np.concatenate([pos_x, neg_x])\n",
    "        ys = np.concatenate([pos_y, neg_y])\n",
    "        ps = np.concatenate([np.ones(len(pos_x)), -np.ones(len(neg_x))])\n",
    "        \n",
    "        return xs, ys, ps, log_change\n",
    "    \n",
    "    # Generate events for each frame transition\n",
    "    all_events = []\n",
    "    log_changes = []\n",
    "    \n",
    "    for i in range(len(frames) - 1):\n",
    "        xs, ys, ps, log_change = generate_events_esim(frames[i], frames[i + 1])\n",
    "        all_events.append((xs, ys, ps))\n",
    "        log_changes.append(log_change)\n",
    "    \n",
    "    # Visualise simulation process\n",
    "    fig, axes = plt.subplots(3, len(frames) - 1, figsize=(15, 9))\n",
    "    if len(frames) - 1 == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for i in range(len(frames) - 1):\n",
    "        # Original frames\n",
    "        axes[0, i].imshow(frames[i], cmap='gray', vmin=0, vmax=1)\n",
    "        axes[0, i].set_title(f'Frame {i}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Log brightness change\n",
    "        im = axes[1, i].imshow(log_changes[i], cmap='RdBu', vmin=-0.5, vmax=0.5)\n",
    "        axes[1, i].set_title(f'Log Change {i}‚Üí{i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Generated events\n",
    "        axes[2, i].imshow(frames[i], cmap='gray', alpha=0.3)\n",
    "        xs, ys, ps = all_events[i]\n",
    "        if len(xs) > 0:\n",
    "            pos_mask = ps > 0\n",
    "            neg_mask = ps < 0\n",
    "            if np.any(pos_mask):\n",
    "                axes[2, i].scatter(xs[pos_mask], ys[pos_mask], c='red', s=20, marker='+', label='Positive')\n",
    "            if np.any(neg_mask):\n",
    "                axes[2, i].scatter(xs[neg_mask], ys[neg_mask], c='blue', s=20, marker='_', label='Negative')\n",
    "        axes[2, i].set_title(f'Events {i}‚Üí{i+1}')\n",
    "        axes[2, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[2, i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Event statistics\n",
    "    total_events = sum(len(events[0]) for events in all_events)\n",
    "    pos_events = sum(np.sum(events[2] > 0) for events in all_events)\n",
    "    neg_events = total_events - pos_events\n",
    "    \n",
    "    print(f\"\\nüìä Simulation Results:\")\n",
    "    print(f\"   Total events generated: {total_events}\")\n",
    "    print(f\"   Positive events: {pos_events} ({pos_events/total_events*100:.1f}%)\")\n",
    "    print(f\"   Negative events: {neg_events} ({neg_events/total_events*100:.1f}%)\")\n",
    "    print(f\"   Average events per transition: {total_events/(len(frames)-1):.1f}\")\n",
    "\n",
    "demonstrate_esim_principles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Simulation Parameters\n",
    "\n",
    "ESIM simulation includes many configurable parameters that affect event generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_simulation_parameters():\n",
    "    \"\"\"Show how different simulation parameters affect event generation\"\"\"\n",
    "    \n",
    "    print(\"ESIM Simulation Parameters:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    parameters = {\n",
    "        \"Positive Threshold (C+)\": {\n",
    "            \"description\": \"Brightness increase threshold for positive events\",\n",
    "            \"typical_range\": \"0.05 - 0.3\",\n",
    "            \"effect\": \"Lower values = more sensitive to brightness increases\"\n",
    "        },\n",
    "        \"Negative Threshold (C-)\": {\n",
    "            \"description\": \"Brightness decrease threshold for negative events\", \n",
    "            \"typical_range\": \"0.05 - 0.3\",\n",
    "            \"effect\": \"Lower values = more sensitive to brightness decreases\"\n",
    "        },\n",
    "        \"Refractory Period\": {\n",
    "            \"description\": \"Minimum time between events at same pixel\",\n",
    "            \"typical_range\": \"0.1 - 5.0 ms\",\n",
    "            \"effect\": \"Prevents rapid firing, mimics biological behaviour\"\n",
    "        },\n",
    "        \"Shot Noise Sigma\": {\n",
    "            \"description\": \"Standard deviation of photon shot noise\",\n",
    "            \"typical_range\": \"0.01 - 0.1\",\n",
    "            \"effect\": \"Adds realistic noise to brightness measurements\"\n",
    "        },\n",
    "        \"Cutoff Frequency\": {\n",
    "            \"description\": \"Low-pass filter frequency for temporal filtering\",\n",
    "            \"typical_range\": \"30 - 300 Hz\",\n",
    "            \"effect\": \"Reduces high-frequency noise and aliasing\"\n",
    "        },\n",
    "        \"Temporal Resolution\": {\n",
    "            \"description\": \"Time resolution for event timestamps\",\n",
    "            \"typical_range\": \"1 - 100 Œºs\",\n",
    "            \"effect\": \"Affects temporal precision of generated events\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for param_name, info in parameters.items():\n",
    "        print(f\"üîß {param_name}:\")\n",
    "        print(f\"   Description: {info['description']}\")\n",
    "        print(f\"   Typical Range: {info['typical_range']}\")\n",
    "        print(f\"   Effect: {info['effect']}\")\n",
    "        print()\n",
    "    \n",
    "    # Demonstrate threshold sensitivity\n",
    "    def test_threshold_sensitivity():\n",
    "        \"\"\"Test how thresholds affect event generation\"\"\"\n",
    "        \n",
    "        # Create test pattern\n",
    "        width, height = 64, 64\n",
    "        frame1 = np.zeros((height, width), dtype=np.float32)\n",
    "        frame2 = np.zeros((height, width), dtype=np.float32)\n",
    "        \n",
    "        # Add gradient pattern\n",
    "        x_coords = np.linspace(0, 1, width)\n",
    "        y_coords = np.linspace(0, 1, height)\n",
    "        X, Y = np.meshgrid(x_coords, y_coords)\n",
    "        \n",
    "        frame1 = 0.3 + 0.2 * X\n",
    "        frame2 = 0.3 + 0.3 * X  # Increased gradient\n",
    "        \n",
    "        # Test different thresholds\n",
    "        thresholds = [0.05, 0.1, 0.2, 0.3]\n",
    "        \n",
    "        fig, axes = plt.subplots(2, len(thresholds), figsize=(15, 6))\n",
    "        \n",
    "        for i, threshold in enumerate(thresholds):\n",
    "            # Compute log change\n",
    "            log_change = np.log(frame2 + 1e-6) - np.log(frame1 + 1e-6)\n",
    "            \n",
    "            # Find events\n",
    "            pos_events = log_change > threshold\n",
    "            neg_events = log_change < -threshold\n",
    "            \n",
    "            # Count events\n",
    "            n_pos = np.sum(pos_events)\n",
    "            n_neg = np.sum(neg_events)\n",
    "            \n",
    "            # Visualise log change\n",
    "            axes[0, i].imshow(log_change, cmap='RdBu', vmin=-0.3, vmax=0.3)\n",
    "            axes[0, i].contour(log_change, levels=[threshold, -threshold], \n",
    "                              colors=['red', 'blue'], linewidths=2)\n",
    "            axes[0, i].set_title(f'Threshold: {threshold:.2f}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Visualise events\n",
    "            event_map = np.zeros_like(log_change)\n",
    "            event_map[pos_events] = 1\n",
    "            event_map[neg_events] = -1\n",
    "            \n",
    "            axes[1, i].imshow(event_map, cmap='RdBu', vmin=-1, vmax=1)\n",
    "            axes[1, i].set_title(f'Events: {n_pos + n_neg} total')\n",
    "            axes[1, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Create threshold sensitivity plot\n",
    "        test_thresholds = np.linspace(0.01, 0.5, 50)\n",
    "        event_counts = []\n",
    "        \n",
    "        for thresh in test_thresholds:\n",
    "            pos_events = np.sum(log_change > thresh)\n",
    "            neg_events = np.sum(log_change < -thresh)\n",
    "            event_counts.append(pos_events + neg_events)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(test_thresholds, event_counts, 'b-', linewidth=2)\n",
    "        plt.xlabel('Threshold Value')\n",
    "        plt.ylabel('Total Events Generated')\n",
    "        plt.title('Event Count vs Threshold Sensitivity')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Mark optimal range\n",
    "        plt.axvspan(0.1, 0.2, alpha=0.2, color='green', label='Typical Range')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    test_threshold_sensitivity()\n",
    "\n",
    "demonstrate_simulation_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Noise Models\n",
    "\n",
    "Realistic event camera simulation includes various noise sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_noise_models():\n",
    "    \"\"\"Demonstrate different noise models in event simulation\"\"\"\n",
    "    \n",
    "    print(\"Event Camera Noise Models:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    noise_types = {\n",
    "        \"Shot Noise\": {\n",
    "            \"description\": \"Photon counting noise following Poisson statistics\",\n",
    "            \"formula\": \"œÉ¬≤ = k √ó I (k: gain, I: intensity)\",\n",
    "            \"characteristics\": \"Signal-dependent, fundamental physical limit\"\n",
    "        },\n",
    "        \"Thermal Noise\": {\n",
    "            \"description\": \"Dark current and thermal electron generation\",\n",
    "            \"formula\": \"œÉ¬≤ = œÉ_thermal¬≤ (constant)\",\n",
    "            \"characteristics\": \"Temperature-dependent, signal-independent\"\n",
    "        },\n",
    "        \"Reset Noise\": {\n",
    "            \"description\": \"Pixel reset mechanism noise\",\n",
    "            \"formula\": \"œÉ¬≤ = kT/C (thermal noise in capacitor)\",\n",
    "            \"characteristics\": \"Pixel-dependent, affects threshold precision\"\n",
    "        },\n",
    "        \"Leakage Current\": {\n",
    "            \"description\": \"Unwanted current flow in pixel circuits\",\n",
    "            \"formula\": \"I_leak = I‚ÇÄ √ó exp(qV/kT)\",\n",
    "            \"characteristics\": \"Temperature and voltage dependent\"\n",
    "        },\n",
    "        \"Background Activity\": {\n",
    "            \"description\": \"Spurious events not related to light changes\",\n",
    "            \"formula\": \"Poisson process with rate Œª_bg\",\n",
    "            \"characteristics\": \"Random temporal distribution\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for noise_name, info in noise_types.items():\n",
    "        print(f\"üîä {noise_name}:\")\n",
    "        print(f\"   Description: {info['description']}\")\n",
    "        print(f\"   Formula: {info['formula']}\")\n",
    "        print(f\"   Characteristics: {info['characteristics']}\")\n",
    "        print()\n",
    "    \n",
    "    # Simulate different noise models\n",
    "    def simulate_noise_effects():\n",
    "        \"\"\"Simulate the effect of different noise models\"\"\"\n",
    "        \n",
    "        # Create clean events from a simple pattern\n",
    "        width, height = 100, 100\n",
    "        n_clean_events = 500\n",
    "        \n",
    "        # Generate clean events in a circular pattern\n",
    "        angles = np.linspace(0, 2*np.pi, n_clean_events)\n",
    "        radius = 20\n",
    "        center = (50, 50)\n",
    "        \n",
    "        clean_x = (center[0] + radius * np.cos(angles)).astype(int)\n",
    "        clean_y = (center[1] + radius * np.sin(angles)).astype(int)\n",
    "        clean_p = np.ones(n_clean_events, dtype=int)\n",
    "        clean_t = np.linspace(0, 1, n_clean_events)\n",
    "        \n",
    "        # Apply different noise models\n",
    "        noise_configs = {\n",
    "            \"No Noise\": {\"shot_sigma\": 0, \"thermal_rate\": 0, \"bg_rate\": 0},\n",
    "            \"Shot Noise Only\": {\"shot_sigma\": 0.1, \"thermal_rate\": 0, \"bg_rate\": 0},\n",
    "            \"Thermal + Shot\": {\"shot_sigma\": 0.1, \"thermal_rate\": 100, \"bg_rate\": 0},\n",
    "            \"All Noise Sources\": {\"shot_sigma\": 0.1, \"thermal_rate\": 100, \"bg_rate\": 50}\n",
    "        }\n",
    "        \n",
    "        fig, axes = plt.subplots(2, len(noise_configs), figsize=(16, 8))\n",
    "        \n",
    "        for i, (config_name, config) in enumerate(noise_configs.items()):\n",
    "            # Start with clean events\n",
    "            noisy_x = clean_x.copy()\n",
    "            noisy_y = clean_y.copy()\n",
    "            noisy_p = clean_p.copy()\n",
    "            noisy_t = clean_t.copy()\n",
    "            \n",
    "            # Add shot noise (spatial displacement)\n",
    "            if config[\"shot_sigma\"] > 0:\n",
    "                noise_x = np.random.normal(0, config[\"shot_sigma\"], len(noisy_x))\n",
    "                noise_y = np.random.normal(0, config[\"shot_sigma\"], len(noisy_y))\n",
    "                noisy_x = np.clip(noisy_x + noise_x, 0, width-1).astype(int)\n",
    "                noisy_y = np.clip(noisy_y + noise_y, 0, height-1).astype(int)\n",
    "            \n",
    "            # Add thermal noise events (random locations)\n",
    "            if config[\"thermal_rate\"] > 0:\n",
    "                n_thermal = np.random.poisson(config[\"thermal_rate\"])\n",
    "                thermal_x = np.random.randint(0, width, n_thermal)\n",
    "                thermal_y = np.random.randint(0, height, n_thermal)\n",
    "                thermal_p = np.random.choice([-1, 1], n_thermal)\n",
    "                thermal_t = np.random.uniform(0, 1, n_thermal)\n",
    "                \n",
    "                noisy_x = np.concatenate([noisy_x, thermal_x])\n",
    "                noisy_y = np.concatenate([noisy_y, thermal_y])\n",
    "                noisy_p = np.concatenate([noisy_p, thermal_p])\n",
    "                noisy_t = np.concatenate([noisy_t, thermal_t])\n",
    "            \n",
    "            # Add background activity\n",
    "            if config[\"bg_rate\"] > 0:\n",
    "                n_bg = np.random.poisson(config[\"bg_rate\"])\n",
    "                bg_x = np.random.randint(0, width, n_bg)\n",
    "                bg_y = np.random.randint(0, height, n_bg)\n",
    "                bg_p = np.random.choice([-1, 1], n_bg)\n",
    "                bg_t = np.random.uniform(0, 1, n_bg)\n",
    "                \n",
    "                noisy_x = np.concatenate([noisy_x, bg_x])\n",
    "                noisy_y = np.concatenate([noisy_y, bg_y])\n",
    "                noisy_p = np.concatenate([noisy_p, bg_p])\n",
    "                noisy_t = np.concatenate([noisy_t, bg_t])\n",
    "            \n",
    "            # Sort by timestamp\n",
    "            sort_idx = np.argsort(noisy_t)\n",
    "            noisy_x = noisy_x[sort_idx]\n",
    "            noisy_y = noisy_y[sort_idx]\n",
    "            noisy_p = noisy_p[sort_idx]\n",
    "            noisy_t = noisy_t[sort_idx]\n",
    "            \n",
    "            # Visualise spatial distribution\n",
    "            axes[0, i].set_xlim(0, width)\n",
    "            axes[0, i].set_ylim(0, height)\n",
    "            \n",
    "            pos_mask = noisy_p > 0\n",
    "            neg_mask = noisy_p < 0\n",
    "            \n",
    "            if np.any(pos_mask):\n",
    "                axes[0, i].scatter(noisy_x[pos_mask], noisy_y[pos_mask], \n",
    "                                 c='red', s=4, alpha=0.7, label='Positive')\n",
    "            if np.any(neg_mask):\n",
    "                axes[0, i].scatter(noisy_x[neg_mask], noisy_y[neg_mask], \n",
    "                                 c='blue', s=4, alpha=0.7, label='Negative')\n",
    "            \n",
    "            axes[0, i].set_title(f'{config_name}\\n{len(noisy_x)} events')\n",
    "            axes[0, i].set_aspect('equal')\n",
    "            axes[0, i].invert_yaxis()\n",
    "            if i == 0:\n",
    "                axes[0, i].legend()\n",
    "            \n",
    "            # Visualise temporal distribution\n",
    "            axes[1, i].hist(noisy_t, bins=50, alpha=0.7, density=True)\n",
    "            axes[1, i].set_title('Event Temporal Distribution')\n",
    "            axes[1, i].set_xlabel('Time')\n",
    "            axes[1, i].set_ylabel('Event Density')\n",
    "            axes[1, i].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Noise analysis\n",
    "        print(\"\\nüìä Noise Analysis:\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        for config_name, config in noise_configs.items():\n",
    "            signal_events = n_clean_events\n",
    "            noise_events = config[\"thermal_rate\"] + config[\"bg_rate\"]\n",
    "            snr = signal_events / max(noise_events, 1)\n",
    "            \n",
    "            print(f\"{config_name}:\")\n",
    "            print(f\"   Signal events: {signal_events}\")\n",
    "            print(f\"   Noise events: {noise_events}\")\n",
    "            print(f\"   SNR: {snr:.2f}\")\n",
    "            print()\n",
    "    \n",
    "    simulate_noise_effects()\n",
    "\n",
    "demonstrate_noise_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Video-to-Events Conversion\n",
    "\n",
    "Convert standard videos to event streams using ESIM simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_video_to_events():\n",
    "    \"\"\"Demonstrate video-to-events conversion\"\"\"\n",
    "    \n",
    "    print(\"Video-to-Events Conversion:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    def create_synthetic_video(width=128, height=128, num_frames=20):\n",
    "        \"\"\"Create a synthetic video sequence for demonstration\"\"\"\n",
    "        \n",
    "        frames = []\n",
    "        for i in range(num_frames):\n",
    "            frame = np.zeros((height, width), dtype=np.float32)\n",
    "            \n",
    "            # Add moving objects\n",
    "            # Moving circle\n",
    "            t = i / num_frames\n",
    "            circle_x = int(width * (0.2 + 0.6 * t))\n",
    "            circle_y = int(height * (0.3 + 0.4 * np.sin(2 * np.pi * t)))\n",
    "            \n",
    "            y, x = np.ogrid[:height, :width]\n",
    "            circle_mask = (x - circle_x)**2 + (y - circle_y)**2 <= 8**2\n",
    "            frame[circle_mask] = 0.8\n",
    "            \n",
    "            # Moving rectangle\n",
    "            rect_x = int(width * (0.8 - 0.6 * t))\n",
    "            rect_y = int(height * 0.7)\n",
    "            frame[rect_y-5:rect_y+5, rect_x-10:rect_x+10] = 0.6\n",
    "            \n",
    "            # Add some texture\n",
    "            texture = 0.1 * np.random.rand(height, width)\n",
    "            frame += texture\n",
    "            \n",
    "            frames.append(np.clip(frame, 0, 1))\n",
    "        \n",
    "        return frames\n",
    "    \n",
    "    def video_to_events_esim(frames, pos_threshold=0.1, neg_threshold=0.1, \n",
    "                           refractory_period=0.001, noise_sigma=0.01):\n",
    "        \"\"\"Convert video frames to events using ESIM\"\"\"\n",
    "        \n",
    "        all_events = []\n",
    "        height, width = frames[0].shape\n",
    "        \n",
    "        # Refractory period tracking\n",
    "        last_event_time = np.full((height, width), -refractory_period)\n",
    "        \n",
    "        # Previous log intensity\n",
    "        prev_log_intensity = np.log(frames[0] + 1e-6)\n",
    "        \n",
    "        for frame_idx in range(1, len(frames)):\n",
    "            current_frame = frames[frame_idx]\n",
    "            current_time = frame_idx / len(frames)  # Normalised time\n",
    "            \n",
    "            # Add noise\n",
    "            if noise_sigma > 0:\n",
    "                current_frame = current_frame + np.random.normal(0, noise_sigma, current_frame.shape)\n",
    "                current_frame = np.clip(current_frame, 0, 1)\n",
    "            \n",
    "            # Compute log intensity change\n",
    "            current_log_intensity = np.log(current_frame + 1e-6)\n",
    "            log_change = current_log_intensity - prev_log_intensity\n",
    "            \n",
    "            # Find candidate events\n",
    "            pos_candidates = log_change > pos_threshold\n",
    "            neg_candidates = log_change < -neg_threshold\n",
    "            \n",
    "            # Apply refractory period\n",
    "            time_since_last = current_time - last_event_time\n",
    "            pos_valid = pos_candidates & (time_since_last > refractory_period)\n",
    "            neg_valid = neg_candidates & (time_since_last > refractory_period)\n",
    "            \n",
    "            # Extract valid events\n",
    "            pos_y, pos_x = np.where(pos_valid)\n",
    "            neg_y, neg_x = np.where(neg_valid)\n",
    "            \n",
    "            # Update last event times\n",
    "            last_event_time[pos_valid] = current_time\n",
    "            last_event_time[neg_valid] = current_time\n",
    "            \n",
    "            # Combine events\n",
    "            if len(pos_x) > 0 or len(neg_x) > 0:\n",
    "                xs = np.concatenate([pos_x, neg_x])\n",
    "                ys = np.concatenate([pos_y, neg_y])\n",
    "                ts = np.full(len(xs), current_time)\n",
    "                ps = np.concatenate([np.ones(len(pos_x)), -np.ones(len(neg_x))])\n",
    "                \n",
    "                all_events.append((xs, ys, ts, ps))\n",
    "            \n",
    "            # Update previous log intensity\n",
    "            prev_log_intensity = current_log_intensity\n",
    "        \n",
    "        return all_events\n",
    "    \n",
    "    # Create and process synthetic video\n",
    "    print(\"üé¨ Creating synthetic video...\")\n",
    "    frames = create_synthetic_video(width=80, height=60, num_frames=15)\n",
    "    print(f\"   Created {len(frames)} frames\")\n",
    "    \n",
    "    # Convert to events with different parameters\n",
    "    configs = {\n",
    "        \"High Sensitivity\": {\"pos_threshold\": 0.05, \"neg_threshold\": 0.05, \"noise_sigma\": 0.01},\n",
    "        \"Medium Sensitivity\": {\"pos_threshold\": 0.1, \"neg_threshold\": 0.1, \"noise_sigma\": 0.02},\n",
    "        \"Low Sensitivity\": {\"pos_threshold\": 0.2, \"neg_threshold\": 0.2, \"noise_sigma\": 0.03}\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for config_name, params in configs.items():\n",
    "        print(f\"‚ö° Converting with {config_name} settings...\")\n",
    "        events = video_to_events_esim(frames, **params)\n",
    "        \n",
    "        # Flatten events\n",
    "        if events:\n",
    "            all_xs = np.concatenate([e[0] for e in events])\n",
    "            all_ys = np.concatenate([e[1] for e in events])\n",
    "            all_ts = np.concatenate([e[2] for e in events])\n",
    "            all_ps = np.concatenate([e[3] for e in events])\n",
    "            results[config_name] = (all_xs, all_ys, all_ts, all_ps)\n",
    "        else:\n",
    "            results[config_name] = (np.array([]), np.array([]), np.array([]), np.array([]))\n",
    "        \n",
    "        print(f\"   Generated {len(results[config_name][0])} events\")\n",
    "    \n",
    "    # Visualise results\n",
    "    fig, axes = plt.subplots(2, len(configs) + 1, figsize=(16, 8))\n",
    "    \n",
    "    # Show sample frames\n",
    "    frame_indices = [0, len(frames)//3, 2*len(frames)//3]\n",
    "    combined_frame = np.mean([frames[i] for i in frame_indices], axis=0)\n",
    "    \n",
    "    axes[0, 0].imshow(combined_frame, cmap='gray')\n",
    "    axes[0, 0].set_title('Average Frame')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[1, 0].hist([f.flatten() for f in frames[::3]], bins=50, alpha=0.7, density=True)\n",
    "    axes[1, 0].set_title('Intensity Distribution')\n",
    "    axes[1, 0].set_xlabel('Pixel Intensity')\n",
    "    axes[1, 0].set_ylabel('Density')\n",
    "    \n",
    "    # Show events for each configuration\n",
    "    for i, (config_name, (xs, ys, ts, ps)) in enumerate(results.items(), 1):\n",
    "        if len(xs) > 0:\n",
    "            # Spatial distribution\n",
    "            axes[0, i].imshow(combined_frame, cmap='gray', alpha=0.3)\n",
    "            pos_mask = ps > 0\n",
    "            neg_mask = ps < 0\n",
    "            \n",
    "            if np.any(pos_mask):\n",
    "                axes[0, i].scatter(xs[pos_mask], ys[pos_mask], c='red', s=2, alpha=0.7)\n",
    "            if np.any(neg_mask):\n",
    "                axes[0, i].scatter(xs[neg_mask], ys[neg_mask], c='blue', s=2, alpha=0.7)\n",
    "            \n",
    "            axes[0, i].set_title(f'{config_name}\\n{len(xs)} events')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Temporal distribution\n",
    "            axes[1, i].hist(ts, bins=30, alpha=0.7, density=True)\n",
    "            axes[1, i].set_title('Event Timing')\n",
    "            axes[1, i].set_xlabel('Time')\n",
    "            axes[1, i].set_ylabel('Event Density')\n",
    "        else:\n",
    "            axes[0, i].text(0.5, 0.5, 'No events\\ngenerated', ha='center', va='center')\n",
    "            axes[0, i].set_title(config_name)\n",
    "            axes[1, i].set_title('No events')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Configuration comparison\n",
    "    print(\"\\nüìä Configuration Comparison:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"{'Configuration':<20} {'Events':<10} {'Pos/Neg Ratio':<15} {'Event Rate'}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for config_name, (xs, ys, ts, ps) in results.items():\n",
    "        if len(ps) > 0:\n",
    "            pos_events = np.sum(ps > 0)\n",
    "            neg_events = np.sum(ps < 0)\n",
    "            ratio = pos_events / max(neg_events, 1)\n",
    "            event_rate = len(ps) / (ts.max() - ts.min()) if len(ts) > 1 else 0\n",
    "        else:\n",
    "            pos_events = neg_events = 0\n",
    "            ratio = 0\n",
    "            event_rate = 0\n",
    "        \n",
    "        print(f\"{config_name:<20} {len(xs):<10} {ratio:<15.2f} {event_rate:.0f} Hz\")\n",
    "\n",
    "demonstrate_video_to_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GStreamer Integration\n",
    "\n",
    "Real-time video processing using GStreamer for webcam and video file input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_gstreamer_integration():\n",
    "    \"\"\"Demonstrate GStreamer integration capabilities\"\"\"\n",
    "    \n",
    "    print(\"GStreamer Integration for Real-Time Event Simulation:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # GStreamer pipeline examples\n",
    "    pipelines = {\n",
    "        \"Webcam Capture\": {\n",
    "            \"pipeline\": \"v4l2src device=/dev/video0 ! videoconvert ! video/x-raw,format=GRAY8 ! appsink\",\n",
    "            \"description\": \"Capture from webcam with grayscale conversion\",\n",
    "            \"use_case\": \"Real-time event generation from live camera\"\n",
    "        },\n",
    "        \"Video File\": {\n",
    "            \"pipeline\": \"filesrc location=video.mp4 ! decodebin ! videoconvert ! video/x-raw,format=GRAY8 ! appsink\",\n",
    "            \"description\": \"Process video file with format conversion\",\n",
    "            \"use_case\": \"Batch processing of recorded videos\"\n",
    "        },\n",
    "        \"Network Stream\": {\n",
    "            \"pipeline\": \"udpsrc port=5000 ! application/x-rtp ! rtpjpegdepay ! jpegdec ! videoconvert ! appsink\",\n",
    "            \"description\": \"Receive network video stream\",\n",
    "            \"use_case\": \"Distributed event processing systems\"\n",
    "        },\n",
    "        \"Test Pattern\": {\n",
    "            \"pipeline\": \"videotestsrc pattern=smpte ! video/x-raw,format=GRAY8,width=640,height=480 ! appsink\",\n",
    "            \"description\": \"Generate test patterns for simulation\",\n",
    "            \"use_case\": \"Algorithm testing and validation\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for name, info in pipelines.items():\n",
    "        print(f\"üé• {name}:\")\n",
    "        print(f\"   Pipeline: {info['pipeline']}\")\n",
    "        print(f\"   Description: {info['description']}\")\n",
    "        print(f\"   Use Case: {info['use_case']}\")\n",
    "        print()\n",
    "    \n",
    "    # Simulate GStreamer processing workflow\n",
    "    def simulate_gstreamer_workflow():\n",
    "        \"\"\"Simulate a GStreamer-based event generation workflow\"\"\"\n",
    "        \n",
    "        print(\"üîÑ Simulating GStreamer Workflow:\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Simulated frame capture from GStreamer\n",
    "        def capture_frames_simulation(source_type=\"webcam\", duration_sec=2):\n",
    "            \"\"\"Simulate frame capture from different sources\"\"\"\n",
    "            \n",
    "            frames = []\n",
    "            fps = 30  # Simulate 30 FPS\n",
    "            num_frames = int(duration_sec * fps)\n",
    "            \n",
    "            print(f\"   Capturing {num_frames} frames from {source_type}...\")\n",
    "            \n",
    "            for i in range(num_frames):\n",
    "                if source_type == \"webcam\":\n",
    "                    # Simulate webcam noise and motion\n",
    "                    frame = 0.5 + 0.1 * np.random.randn(120, 160)\n",
    "                    # Add moving object\n",
    "                    t = i / num_frames\n",
    "                    cx = int(160 * (0.2 + 0.6 * t))\n",
    "                    cy = int(60 + 20 * np.sin(4 * np.pi * t))\n",
    "                    frame[cy-10:cy+10, cx-10:cx+10] += 0.3\n",
    "                    \n",
    "                elif source_type == \"video_file\":\n",
    "                    # Simulate more structured motion\n",
    "                    frame = 0.3 * np.ones((120, 160))\n",
    "                    t = i / num_frames\n",
    "                    # Rotating pattern\n",
    "                    angle = 2 * np.pi * t\n",
    "                    for r in range(20, 40, 5):\n",
    "                        x = 80 + int(r * np.cos(angle))\n",
    "                        y = 60 + int(r * np.sin(angle))\n",
    "                        if 0 <= x < 160 and 0 <= y < 120:\n",
    "                            frame[y-2:y+2, x-2:x+2] = 0.8\n",
    "                \n",
    "                elif source_type == \"test_pattern\":\n",
    "                    # SMPTE color bars simulation (grayscale)\n",
    "                    frame = np.zeros((120, 160))\n",
    "                    bar_width = 160 // 7\n",
    "                    intensities = [1.0, 0.85, 0.7, 0.55, 0.4, 0.25, 0.1]\n",
    "                    for j, intensity in enumerate(intensities):\n",
    "                        start_x = j * bar_width\n",
    "                        end_x = min((j + 1) * bar_width, 160)\n",
    "                        frame[:, start_x:end_x] = intensity\n",
    "                    \n",
    "                    # Add moving indicator\n",
    "                    indicator_x = int(160 * (i / num_frames))\n",
    "                    frame[100:110, indicator_x:indicator_x+2] = 0.0\n",
    "                \n",
    "                frame = np.clip(frame, 0, 1)\n",
    "                frames.append(frame)\n",
    "            \n",
    "            return frames\n",
    "        \n",
    "        # Test different sources\n",
    "        sources = [\"webcam\", \"video_file\", \"test_pattern\"]\n",
    "        \n",
    "        fig, axes = plt.subplots(len(sources), 4, figsize=(16, 12))\n",
    "        \n",
    "        for i, source in enumerate(sources):\n",
    "            print(f\"\\nüìπ Processing {source} source...\")\n",
    "            \n",
    "            # Capture frames\n",
    "            frames = capture_frames_simulation(source, duration_sec=1)\n",
    "            \n",
    "            # Convert to events\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Simulate ESIM conversion (simplified)\n",
    "            all_events = []\n",
    "            prev_frame = frames[0]\n",
    "            \n",
    "            for frame_idx, frame in enumerate(frames[1:], 1):\n",
    "                log_change = np.log(frame + 1e-6) - np.log(prev_frame + 1e-6)\n",
    "                pos_events = log_change > 0.1\n",
    "                neg_events = log_change < -0.1\n",
    "                \n",
    "                pos_y, pos_x = np.where(pos_events)\n",
    "                neg_y, neg_x = np.where(neg_events)\n",
    "                \n",
    "                if len(pos_x) > 0 or len(neg_x) > 0:\n",
    "                    xs = np.concatenate([pos_x, neg_x])\n",
    "                    ys = np.concatenate([pos_y, neg_y])\n",
    "                    ps = np.concatenate([np.ones(len(pos_x)), -np.ones(len(neg_x))])\n",
    "                    ts = np.full(len(xs), frame_idx / len(frames))\n",
    "                    all_events.append((xs, ys, ts, ps))\n",
    "                \n",
    "                prev_frame = frame\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # Combine all events\n",
    "            if all_events:\n",
    "                all_xs = np.concatenate([e[0] for e in all_events])\n",
    "                all_ys = np.concatenate([e[1] for e in all_events])\n",
    "                all_ts = np.concatenate([e[2] for e in all_events])\n",
    "                all_ps = np.concatenate([e[3] for e in all_events])\n",
    "            else:\n",
    "                all_xs = all_ys = all_ts = all_ps = np.array([])\n",
    "            \n",
    "            print(f\"   Generated {len(all_xs)} events in {processing_time:.3f}s\")\n",
    "            print(f\"   Processing rate: {len(frames)/processing_time:.1f} FPS\")\n",
    "            \n",
    "            # Visualise results\n",
    "            # Sample frames\n",
    "            sample_frames = [frames[0], frames[len(frames)//3], frames[2*len(frames)//3]]\n",
    "            for j, frame in enumerate(sample_frames):\n",
    "                if j < 3:\n",
    "                    axes[i, j].imshow(frame, cmap='gray')\n",
    "                    axes[i, j].set_title(f'{source.title()}\\nFrame {j*len(frames)//3}')\n",
    "                    axes[i, j].axis('off')\n",
    "            \n",
    "            # Events overlay\n",
    "            axes[i, 3].imshow(frames[-1], cmap='gray', alpha=0.3)\n",
    "            if len(all_xs) > 0:\n",
    "                pos_mask = all_ps > 0\n",
    "                neg_mask = all_ps < 0\n",
    "                if np.any(pos_mask):\n",
    "                    axes[i, 3].scatter(all_xs[pos_mask], all_ys[pos_mask], \n",
    "                                     c='red', s=1, alpha=0.7)\n",
    "                if np.any(neg_mask):\n",
    "                    axes[i, 3].scatter(all_xs[neg_mask], all_ys[neg_mask], \n",
    "                                     c='blue', s=1, alpha=0.7)\n",
    "            axes[i, 3].set_title(f'Events\\n{len(all_xs)} total')\n",
    "            axes[i, 3].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Performance summary\n",
    "        print(\"\\n‚ö° GStreamer Integration Benefits:\")\n",
    "        print(\"=\" * 40)\n",
    "        benefits = [\n",
    "            \"Cross-platform video capture and processing\",\n",
    "            \"Hardware-accelerated video decoding\",\n",
    "            \"Support for multiple video formats and codecs\",\n",
    "            \"Network streaming capabilities\",\n",
    "            \"Low-latency pipeline processing\",\n",
    "            \"Modular plugin architecture\"\n",
    "        ]\n",
    "        \n",
    "        for benefit in benefits:\n",
    "            print(f\"   ‚úÖ {benefit}\")\n",
    "    \n",
    "    simulate_gstreamer_workflow()\n",
    "\n",
    "demonstrate_gstreamer_integration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Event Quality Metrics and Validation\n",
    "\n",
    "Evaluate the quality and realism of simulated events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_event_quality_metrics():\n",
    "    \"\"\"Demonstrate event quality assessment and validation\"\"\"\n",
    "    \n",
    "    print(\"Event Quality Metrics and Validation:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Quality metrics\n",
    "    metrics = {\n",
    "        \"Temporal Consistency\": {\n",
    "            \"description\": \"Events should follow natural temporal patterns\",\n",
    "            \"measurement\": \"Inter-spike interval distribution analysis\",\n",
    "            \"good_range\": \"Exponential decay with realistic refractory period\"\n",
    "        },\n",
    "        \"Spatial Correlation\": {\n",
    "            \"description\": \"Events should correlate with visual features\",\n",
    "            \"measurement\": \"Cross-correlation with edge maps\",\n",
    "            \"good_range\": \"Correlation coefficient > 0.7\"\n",
    "        },\n",
    "        \"Polarity Balance\": {\n",
    "            \"description\": \"Positive and negative events should be balanced\",\n",
    "            \"measurement\": \"Ratio of positive to negative events\",\n",
    "            \"good_range\": \"0.8 - 1.2 for natural scenes\"\n",
    "        },\n",
    "        \"Event Rate Statistics\": {\n",
    "            \"description\": \"Event rates should match expected camera characteristics\",\n",
    "            \"measurement\": \"Events per second distribution\",\n",
    "            \"good_range\": \"1K - 100K events/sec depending on scene dynamics\"\n",
    "        },\n",
    "        \"Noise Characteristics\": {\n",
    "            \"description\": \"Background noise should follow realistic patterns\",\n",
    "            \"measurement\": \"Spatial and temporal noise analysis\",\n",
    "            \"good_range\": \"< 10% background activity for well-lit scenes\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for metric_name, info in metrics.items():\n",
    "        print(f\"üìä {metric_name}:\")\n",
    "        print(f\"   Description: {info['description']}\")\n",
    "        print(f\"   Measurement: {info['measurement']}\")\n",
    "        print(f\"   Good Range: {info['good_range']}\")\n",
    "        print()\n",
    "    \n",
    "    # Generate test events for validation\n",
    "    def generate_test_events(event_type=\"realistic\"):\n",
    "        \"\"\"Generate test events with different characteristics\"\"\"\n",
    "        \n",
    "        if event_type == \"realistic\":\n",
    "            # Realistic event pattern\n",
    "            n_events = 2000\n",
    "            width, height = 128, 128\n",
    "            \n",
    "            # Events following edges and motion\n",
    "            xs = []\n",
    "            ys = []\n",
    "            ts = []\n",
    "            ps = []\n",
    "            \n",
    "            # Horizontal edge\n",
    "            for i in range(500):\n",
    "                x = np.random.randint(0, width)\n",
    "                y = 40 + np.random.randint(-2, 3)\n",
    "                t = np.random.exponential(0.1)\n",
    "                p = np.random.choice([-1, 1])\n",
    "                xs.extend([x]); ys.extend([y]); ts.extend([t]); ps.extend([p])\n",
    "            \n",
    "            # Vertical edge  \n",
    "            for i in range(500):\n",
    "                x = 60 + np.random.randint(-2, 3)\n",
    "                y = np.random.randint(0, height)\n",
    "                t = 0.5 + np.random.exponential(0.1)\n",
    "                p = np.random.choice([-1, 1])\n",
    "                xs.extend([x]); ys.extend([y]); ts.extend([t]); ps.extend([p])\n",
    "            \n",
    "            # Random noise\n",
    "            for i in range(200):\n",
    "                x = np.random.randint(0, width)\n",
    "                y = np.random.randint(0, height)\n",
    "                t = np.random.uniform(0, 1)\n",
    "                p = np.random.choice([-1, 1])\n",
    "                xs.extend([x]); ys.extend([y]); ts.extend([t]); ps.extend([p])\n",
    "            \n",
    "        elif event_type == \"noisy\":\n",
    "            # Very noisy events\n",
    "            n_events = 3000\n",
    "            xs = np.random.randint(0, 128, n_events)\n",
    "            ys = np.random.randint(0, 128, n_events)\n",
    "            ts = np.random.uniform(0, 1, n_events)\n",
    "            ps = np.random.choice([-1, 1], n_events)\n",
    "            \n",
    "        elif event_type == \"sparse\":\n",
    "            # Very few events\n",
    "            n_events = 50\n",
    "            xs = np.random.randint(20, 108, n_events)  # Central region\n",
    "            ys = np.random.randint(20, 108, n_events)\n",
    "            ts = np.sort(np.random.uniform(0, 1, n_events))\n",
    "            ps = np.random.choice([-1, 1], n_events)\n",
    "        \n",
    "        # Sort by timestamp\n",
    "        sort_idx = np.argsort(ts)\n",
    "        xs = np.array(xs)[sort_idx]\n",
    "        ys = np.array(ys)[sort_idx]\n",
    "        ts = np.array(ts)[sort_idx]\n",
    "        ps = np.array(ps)[sort_idx]\n",
    "        \n",
    "        return xs, ys, ts, ps\n",
    "    \n",
    "    # Evaluate different event sets\n",
    "    event_types = [\"realistic\", \"noisy\", \"sparse\"]\n",
    "    results = {}\n",
    "    \n",
    "    for event_type in event_types:\n",
    "        xs, ys, ts, ps = generate_test_events(event_type)\n",
    "        \n",
    "        # Compute quality metrics\n",
    "        metrics = {}\n",
    "        \n",
    "        # 1. Temporal consistency (inter-spike intervals)\n",
    "        if len(ts) > 1:\n",
    "            intervals = np.diff(ts)\n",
    "            metrics['avg_interval'] = np.mean(intervals)\n",
    "            metrics['interval_std'] = np.std(intervals)\n",
    "        else:\n",
    "            metrics['avg_interval'] = metrics['interval_std'] = 0\n",
    "        \n",
    "        # 2. Polarity balance\n",
    "        pos_events = np.sum(ps > 0)\n",
    "        neg_events = np.sum(ps < 0)\n",
    "        metrics['polarity_ratio'] = pos_events / max(neg_events, 1)\n",
    "        \n",
    "        # 3. Event rate\n",
    "        if len(ts) > 1:\n",
    "            duration = ts[-1] - ts[0]\n",
    "            metrics['event_rate'] = len(ts) / max(duration, 1e-6)\n",
    "        else:\n",
    "            metrics['event_rate'] = 0\n",
    "        \n",
    "        # 4. Spatial distribution uniformity\n",
    "        spatial_hist, _, _ = np.histogram2d(xs, ys, bins=16)\n",
    "        metrics['spatial_entropy'] = -np.sum(spatial_hist * np.log(spatial_hist + 1e-10))\n",
    "        \n",
    "        # 5. Temporal regularity\n",
    "        if len(ts) > 10:\n",
    "            # Autocorrelation of event times\n",
    "            time_series = np.histogram(ts, bins=50)[0]\n",
    "            autocorr = np.correlate(time_series, time_series, mode='full')\n",
    "            metrics['temporal_regularity'] = np.std(autocorr) / np.mean(autocorr)\n",
    "        else:\n",
    "            metrics['temporal_regularity'] = 0\n",
    "        \n",
    "        results[event_type] = {\n",
    "            'events': (xs, ys, ts, ps),\n",
    "            'metrics': metrics\n",
    "        }\n",
    "    \n",
    "    # Visualise quality assessment\n",
    "    fig, axes = plt.subplots(3, len(event_types), figsize=(15, 12))\n",
    "    \n",
    "    for i, event_type in enumerate(event_types):\n",
    "        xs, ys, ts, ps = results[event_type]['events']\n",
    "        metrics = results[event_type]['metrics']\n",
    "        \n",
    "        # Spatial distribution\n",
    "        axes[0, i].set_xlim(0, 128)\n",
    "        axes[0, i].set_ylim(0, 128)\n",
    "        \n",
    "        if len(xs) > 0:\n",
    "            pos_mask = ps > 0\n",
    "            neg_mask = ps < 0\n",
    "            if np.any(pos_mask):\n",
    "                axes[0, i].scatter(xs[pos_mask], ys[pos_mask], c='red', s=2, alpha=0.6)\n",
    "            if np.any(neg_mask):\n",
    "                axes[0, i].scatter(xs[neg_mask], ys[neg_mask], c='blue', s=2, alpha=0.6)\n",
    "        \n",
    "        axes[0, i].set_title(f'{event_type.title()} Events\\n{len(xs)} total')\n",
    "        axes[0, i].set_aspect('equal')\n",
    "        axes[0, i].invert_yaxis()\n",
    "        \n",
    "        # Temporal distribution\n",
    "        if len(ts) > 0:\n",
    "            axes[1, i].hist(ts, bins=30, alpha=0.7, density=True)\n",
    "            axes[1, i].set_title(f'Temporal Distribution\\nRate: {metrics[\"event_rate\"]:.0f} Hz')\n",
    "            axes[1, i].set_xlabel('Time')\n",
    "            axes[1, i].set_ylabel('Event Density')\n",
    "        \n",
    "        # Inter-spike intervals\n",
    "        if len(ts) > 1:\n",
    "            intervals = np.diff(ts)\n",
    "            axes[2, i].hist(intervals, bins=30, alpha=0.7, density=True)\n",
    "            axes[2, i].set_title(f'Inter-spike Intervals\\nMean: {metrics[\"avg_interval\"]:.3f}s')\n",
    "            axes[2, i].set_xlabel('Interval (s)')\n",
    "            axes[2, i].set_ylabel('Density')\n",
    "            axes[2, i].set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Quality assessment summary\n",
    "    print(\"\\nüéØ Quality Assessment Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'Event Type':<12} {'Events':<8} {'Pol.Ratio':<10} {'Rate(Hz)':<10} {'Spatial Ent.':<12} {'Quality'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for event_type in event_types:\n",
    "        metrics = results[event_type]['metrics']\n",
    "        xs, ys, ts, ps = results[event_type]['events']\n",
    "        \n",
    "        # Simple quality score\n",
    "        quality_score = 0\n",
    "        if 0.8 <= metrics['polarity_ratio'] <= 1.2:\n",
    "            quality_score += 1\n",
    "        if 1000 <= metrics['event_rate'] <= 10000:\n",
    "            quality_score += 1\n",
    "        if metrics['spatial_entropy'] > 5:\n",
    "            quality_score += 1\n",
    "        \n",
    "        quality_rating = ['Poor', 'Fair', 'Good', 'Excellent'][quality_score]\n",
    "        \n",
    "        print(f\"{event_type:<12} {len(xs):<8} {metrics['polarity_ratio']:<10.2f} \"\n",
    "              f\"{metrics['event_rate']:<10.0f} {metrics['spatial_entropy']:<12.1f} {quality_rating}\")\n",
    "\n",
    "demonstrate_event_quality_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated evlib's comprehensive event simulation capabilities:\n",
    "\n",
    "‚úÖ **ESIM-style simulation**: Biologically-inspired event generation  \n",
    "‚úÖ **Advanced parameters**: Configurable thresholds and noise models  \n",
    "‚úÖ **Realistic noise models**: Shot noise, thermal noise, background activity  \n",
    "‚úÖ **Video-to-events conversion**: Process any video format  \n",
    "‚úÖ **GStreamer integration**: Real-time webcam and network streams  \n",
    "‚úÖ **Quality validation**: Comprehensive metrics and assessment tools  \n",
    "\n",
    "The simulation system enables researchers to:\n",
    "- Generate realistic event data for algorithm development\n",
    "- Test event-based algorithms without expensive hardware\n",
    "- Create large-scale datasets for machine learning\n",
    "- Validate algorithms under controlled conditions\n",
    "- Bridge the gap between traditional and event-based computer vision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
